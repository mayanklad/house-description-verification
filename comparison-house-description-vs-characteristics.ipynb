{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mayanklad/comparison-house-description-vs-characteristics?scriptVersionId=143690854\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## **Introduction:** Determine whether a house's description accurately matches its listed characteristics\n- This case study aims to demonstrate the understanding of various AI and Machine learning tools used for data cleaning, data wrangling, data scraping, data visualization and modeling in Python.\n- Focuses on using web scraping techniques using Beautiful Soup library to extract real estate listings of Rome from an Italian real estate website, immobiliare.it.\n- Performs a clustering analysis on the house's given description as the first clustering group (the description cluster or TF-IDF cluster) and five other attributes of the house listing ('price', 'rooms', 'surface', 'bathrooms', 'floor') as the second clustering group (the feature cluster) to compare the similarity between them.\n- Thus, this analysis would help to decide how effectively the house's given description reflect the actual attributes of a house listing.","metadata":{"id":"n6t_YKPuLwN1"}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"id":"8c349958"}},{"cell_type":"code","source":"# Data\nimport numpy as np\nimport pandas as pd\nimport lxml\nfrom bs4 import BeautifulSoup\n\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\nfrom ydata_profiling import ProfileReport\n\n\n# Data Preprocessing\nimport re\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import wordnet\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n# Model\nfrom sklearn.cluster import KMeans\n\n\n# Misc\nimport string\nimport math\nfrom os import path\nimport warnings\nimport requests\nfrom collections import defaultdict\nfrom time import sleep\nfrom tqdm.auto import tqdm","metadata":{"id":"b08f6ad8","execution":{"iopub.status.busy":"2023-09-20T22:55:29.507415Z","iopub.execute_input":"2023-09-20T22:55:29.508699Z","iopub.status.idle":"2023-09-20T22:55:35.93809Z","shell.execute_reply.started":"2023-09-20T22:55:29.50864Z","shell.execute_reply":"2023-09-20T22:55:35.936678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('all')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T22:55:35.940865Z","iopub.execute_input":"2023-09-20T22:55:35.941554Z","iopub.status.idle":"2023-09-20T22:55:57.846954Z","shell.execute_reply.started":"2023-09-20T22:55:35.941518Z","shell.execute_reply":"2023-09-20T22:55:57.845672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"id":"6894a2db","execution":{"iopub.status.busy":"2023-09-20T22:55:57.848472Z","iopub.execute_input":"2023-09-20T22:55:57.848874Z","iopub.status.idle":"2023-09-20T22:55:57.855237Z","shell.execute_reply.started":"2023-09-20T22:55:57.84884Z","shell.execute_reply":"2023-09-20T22:55:57.853558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scraping the Data\n","metadata":{"id":"5399ee33"}},{"cell_type":"markdown","source":"### About the Data Source\n- The dataset has been obtained by scraping data from an Italian real estate website (‘https://www.immobiliare.it/en’) by using the Beautiful Soup library. \n- It contains real estate listings from the city of Rome.\n- After scraping data, we obtained 1665 listings which means our dataset contains 1665 rows and 7 columns. \n\n\n","metadata":{"id":"HnjwrmDUgxcS"}},{"cell_type":"code","source":"mainpage = 'https://www.immobiliare.it/en'","metadata":{"id":"7b3ce450","execution":{"iopub.status.busy":"2023-09-20T22:55:57.856851Z","iopub.execute_input":"2023-09-20T22:55:57.857734Z","iopub.status.idle":"2023-09-20T22:55:57.871689Z","shell.execute_reply.started":"2023-09-20T22:55:57.857689Z","shell.execute_reply":"2023-09-20T22:55:57.870117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Firstly, a function of created to scrape the data from the site www.immobiliare.it and storing it as a csv file.","metadata":{"id":"yHoW6zLzMIEY"}},{"cell_type":"code","source":"def get_listing(listing):\n    '''\n    Returns the features of a listing.\n\n    Parameters:\n        listing (bs4.element.Tag):The object corresponds to an XML or HTML tag of listing.\n\n    Returns:\n        list:The list of features of the listing.   \n    '''\n    \n    title = listing.find('a', class_='in-card__title').get('title')\n    link = listing.find('a', class_='in-card__title').get('href')\n        \n    rooms, surface, bathrooms, floor = 'NA','NA','NA','NA'\n\n    if not link.startswith('https://www.immobiliare.it/en'):\n        link = mainpage + link\n        \n    sub_content = requests.get(link)\n    sub_soup = BeautifulSoup(sub_content.text, \"html.parser\")\n    \n    infos = sub_soup.find('ul', class_='nd-list nd-list--pipe in-feat in-feat--full in-feat__mainProperty in-landingDetail__mainFeatures')\n    \n    price = infos.find('li', class_='nd-list__item in-feat__item in-feat__item--main in-detail__mainFeaturesPrice')    \n    price = price.getText()    \n\n    sub_infos = infos.find_all('div', class_='in-feat__data')\n    \n    rooms = sub_infos[0].getText()\n    surface = sub_infos[1].getText()\n    bathrooms = sub_infos[2].getText()\n    floor = sub_infos[3].getText()\n\n    description = sub_soup.find('div', class_='in-readAll').div.getText()\n\n    features = [title, price, rooms, surface, bathrooms, floor, description]\n    \n    sleep(1) # We apply thread sleep to allow the next request to return a response\n    \n    return features\n","metadata":{"id":"d26c6fa1","execution":{"iopub.status.busy":"2023-09-20T22:55:57.876902Z","iopub.execute_input":"2023-09-20T22:55:57.877312Z","iopub.status.idle":"2023-09-20T22:55:57.891001Z","shell.execute_reply.started":"2023-09-20T22:55:57.877279Z","shell.execute_reply":"2023-09-20T22:55:57.889254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we iterate over each listing by calling another function that scrapes the seven features of the property. Each house listing is further saved to the “raw_data.csv” file.","metadata":{"id":"UMGo3bnsMOx2"}},{"cell_type":"code","source":"def scraping_function():\n    '''\n    Function to scrap the data and save it as a csv file.\n\n    Returns:\n        pandas.DataFrame:DataFrame object consisting of the scraped listings.   \n    '''\n    counter=0\n    listings = []\n    columns = ['title', 'price', 'rooms', 'surface', 'bathrooms', 'floor','description']\n\n    # There are 80 pages in search results\n    for page_num in tqdm(range(1, 81)):\n\n        # requesting for the html page\n        web_page = requests.get(f'https://www.immobiliare.it/en/vendita-case/roma/?criterio=rilevanza&pag={page_num}')\n        \n        # soupifying\n        soup = BeautifulSoup(web_page.text, 'lxml')\n\n        # find all the tags li with class 'nd-list__item in-realEstateResults__item' which are individual listings\n        listings_html = soup.find_all('li', class_ = 'nd-list__item in-realEstateResults__item')\n\n        for listing in listings_html:\n            try:\n                features = get_listing(listing)\n                listings.append(features)\n                counter += 1\n                \n            except:\n                # Error in scraping the listing and moving on to the next one\n                pass\n\n            if counter == 10000: # Save the data to csv if fetched 10000 listings and stop the scraping\n                df = pd.DataFrame(listings, columns=columns)\n                df.to_csv('raw_data.csv', index=False)\n                \n                return df\n    \n    df = pd.DataFrame(listings, columns=columns)\n    df.to_csv('raw_data.csv', index=False)\n    \n    print(f'{counter} listings were scraped successfully!')\n    \n    return df\n","metadata":{"id":"892066c2","execution":{"iopub.status.busy":"2023-09-20T22:55:57.89284Z","iopub.execute_input":"2023-09-20T22:55:57.893252Z","iopub.status.idle":"2023-09-20T22:55:57.912827Z","shell.execute_reply.started":"2023-09-20T22:55:57.893218Z","shell.execute_reply":"2023-09-20T22:55:57.911842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not path.exists('raw_data.csv') and not path.exists('/kaggle/input/rome-real-estate-listings/raw_data.csv'):\n    df = scraping_function()\nelse:\n    print('Data already scraped! Use the stored CSV file.')","metadata":{"id":"8a8a6f56","outputId":"cca9a767-a542-42a8-c2cc-c3bb299d8d23","execution":{"iopub.status.busy":"2023-09-20T22:55:57.913904Z","iopub.execute_input":"2023-09-20T22:55:57.914313Z","iopub.status.idle":"2023-09-20T22:55:57.945201Z","shell.execute_reply.started":"2023-09-20T22:55:57.914283Z","shell.execute_reply":"2023-09-20T22:55:57.943766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{"id":"4d17b4e7"}},{"cell_type":"markdown","source":"Loading the scraped data (saved datafile) and inserting the columns names","metadata":{"id":"Tdyku0GT5yHf"}},{"cell_type":"code","source":"columns = ['title', 'price', 'rooms', 'surface', 'bathrooms', 'floor','description']\nif path.exists('raw_data.csv'):\n    df = pd.read_csv('data/raw_data.csv', header=None, skiprows=1, names=columns)\nelse:\n    df = pd.read_csv('/kaggle/input/rome-real-estate-listings/raw_data.csv', header=None, skiprows=1, names=columns)\n\ndf","metadata":{"id":"fe066b47","outputId":"3812810f-5037-4219-8fef-bfd7ebc4b1a0","execution":{"iopub.status.busy":"2023-09-20T22:55:57.947128Z","iopub.execute_input":"2023-09-20T22:55:57.947642Z","iopub.status.idle":"2023-09-20T22:55:58.082043Z","shell.execute_reply.started":"2023-09-20T22:55:57.947599Z","shell.execute_reply":"2023-09-20T22:55:58.080844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, to observe any missing values. ","metadata":{"id":"G0hKHM4h6vQX"}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"id":"653ddb96","outputId":"1d398595-f9ac-438e-9d1c-6405ad80e5cc","execution":{"iopub.status.busy":"2023-09-20T22:55:58.084245Z","iopub.execute_input":"2023-09-20T22:55:58.085278Z","iopub.status.idle":"2023-09-20T22:55:58.096672Z","shell.execute_reply.started":"2023-09-20T22:55:58.085241Z","shell.execute_reply":"2023-09-20T22:55:58.095525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are missing values in the \"floor\" column. ","metadata":{"id":"RHyGhICc647a"}},{"cell_type":"markdown","source":"## Data Wrangling","metadata":{"id":"ef0ad1aa"}},{"cell_type":"markdown","source":"### Initial Missing values handling","metadata":{"id":"7d7910d0"}},{"cell_type":"markdown","source":"#### Plot to show the non-null values count","metadata":{"id":"f72ab4d5"}},{"cell_type":"code","source":"fig = msno.bar(df, color=(233/255, 114/255, 77/255))","metadata":{"id":"b1ebd75e","outputId":"14b46957-02aa-4ca2-d500-3c959a2b206c","execution":{"iopub.status.busy":"2023-09-20T22:55:58.100235Z","iopub.execute_input":"2023-09-20T22:55:58.100987Z","iopub.status.idle":"2023-09-20T22:55:59.783593Z","shell.execute_reply.started":"2023-09-20T22:55:58.100949Z","shell.execute_reply":"2023-09-20T22:55:59.781772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dropping the null values","metadata":{"id":"f106540a"}},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"id":"ab5c2575","execution":{"iopub.status.busy":"2023-09-20T22:55:59.785893Z","iopub.execute_input":"2023-09-20T22:55:59.787066Z","iopub.status.idle":"2023-09-20T22:55:59.802433Z","shell.execute_reply.started":"2023-09-20T22:55:59.786956Z","shell.execute_reply":"2023-09-20T22:55:59.800973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing the `price` column","metadata":{"id":"2bdd5013"}},{"cell_type":"code","source":"df[df.price.str.contains('[a-zA-Z]') == True].head()","metadata":{"id":"158a4d3a","outputId":"392a64a5-ef28-487d-cb9c-26b6ae9429b2","execution":{"iopub.status.busy":"2023-09-20T22:55:59.803971Z","iopub.execute_input":"2023-09-20T22:55:59.804466Z","iopub.status.idle":"2023-09-20T22:56:00.795047Z","shell.execute_reply.started":"2023-09-20T22:55:59.80442Z","shell.execute_reply":"2023-09-20T22:56:00.794038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see there are listings which have **price** values as **Price on application** which needs to be handled.","metadata":{"id":"574a5791"}},{"cell_type":"markdown","source":"#### Removing 'Price on application' from 'price'","metadata":{"id":"bc2403bb"}},{"cell_type":"code","source":"df = df[df.price.str.contains('[a-zA-Z]') == False]","metadata":{"id":"0c751c3a","execution":{"iopub.status.busy":"2023-09-20T22:56:00.796696Z","iopub.execute_input":"2023-09-20T22:56:00.797417Z","iopub.status.idle":"2023-09-20T22:56:00.877302Z","shell.execute_reply.started":"2023-09-20T22:56:00.797384Z","shell.execute_reply":"2023-09-20T22:56:00.874921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Transforming and formatting the price","metadata":{"id":"6b2cad06"}},{"cell_type":"markdown","source":"Since price is in the form of string with format **€ 100,000**, we have to transform it into 100000.0 a floating value.","metadata":{"id":"087034bc"}},{"cell_type":"code","source":"def price_prep(price):\n    '''\n    Function to preprocess price feature.\n    \n    Parameters:\n        price (str):The string containing the price.\n\n\n    Returns:\n        float:Price value in float   \n    '''\n    # removing punctuation and symbols\n    price = price.replace(',','')\n    price = price.replace('€','')\n    \n    price = price.strip()\n    price = price.split('-')    # if price is in range eg. 80000 - 100000 then we split it into two.\n    \n    if len(price) == 1: # This represents no price range i.e. it is single value.\n        return float(price[0])\n    \n    else: # If we have two values i.e. price range then compute their average\n        min_price = float(price[0])\n        max_price = float(price[1])\n        return (min_price + max_price) / 2","metadata":{"id":"90086103","execution":{"iopub.status.busy":"2023-09-20T22:56:00.887678Z","iopub.execute_input":"2023-09-20T22:56:00.888373Z","iopub.status.idle":"2023-09-20T22:56:00.95047Z","shell.execute_reply.started":"2023-09-20T22:56:00.888333Z","shell.execute_reply":"2023-09-20T22:56:00.949493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.price = df.price.map(price_prep)\ndf.head()","metadata":{"id":"b72465a0","outputId":"69700936-1248-439d-81d0-6bee1271d998","execution":{"iopub.status.busy":"2023-09-20T22:56:00.954146Z","iopub.execute_input":"2023-09-20T22:56:00.954615Z","iopub.status.idle":"2023-09-20T22:56:01.05613Z","shell.execute_reply.started":"2023-09-20T22:56:00.954582Z","shell.execute_reply":"2023-09-20T22:56:01.055032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing the `rooms` column","metadata":{"id":"25152494"}},{"cell_type":"markdown","source":"For the values in the “rooms” column, the ‘+’ was removed where present and in the case where a range was shown such as ‘1-5’, the last value was taken. ","metadata":{"id":"gNaHBevmMfeW"}},{"cell_type":"code","source":"def rooms_prep(rooms):\n    '''\n    Function to preprocess rooms feature.\n    \n    Parameters:\n        rooms (str):The string containing the rooms.\n\n\n    Returns:\n        int:Rooms value in int   \n    '''\n    rooms = rooms.strip()\n    rooms = rooms.replace('+','') # If values is in the form of 1+ then remove the +\n    \n    # usually there's only one value. In case we have a range, for instance '1 - 5', we pick the last value.\n    return int(rooms[-1])","metadata":{"id":"a969f4e1","execution":{"iopub.status.busy":"2023-09-20T22:56:01.057737Z","iopub.execute_input":"2023-09-20T22:56:01.059188Z","iopub.status.idle":"2023-09-20T22:56:01.084018Z","shell.execute_reply.started":"2023-09-20T22:56:01.059148Z","shell.execute_reply":"2023-09-20T22:56:01.082695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rooms = df.rooms.map(rooms_prep)\ndf.head()","metadata":{"id":"2443925e","outputId":"9a05b10e-d673-4b28-d02e-118a73415d64","execution":{"iopub.status.busy":"2023-09-20T22:56:01.086137Z","iopub.execute_input":"2023-09-20T22:56:01.087103Z","iopub.status.idle":"2023-09-20T22:56:01.158183Z","shell.execute_reply.started":"2023-09-20T22:56:01.087061Z","shell.execute_reply":"2023-09-20T22:56:01.156537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing the `surface` column ","metadata":{"id":"5ab6d209"}},{"cell_type":"markdown","source":"This column refers to surface area and values contained m² This was removed using regular expression to substitute a blank space and maintain numerical values. ","metadata":{"id":"e3848103"}},{"cell_type":"code","source":"# removing m²\ndf.surface = df.surface.map(lambda x: float(re.sub(r'\\D', '', x)))\ndf.head(5)","metadata":{"id":"4bb0c90f","outputId":"13c658ca-664c-46dd-c691-22e5bbd69ceb","execution":{"iopub.status.busy":"2023-09-20T22:56:01.160355Z","iopub.execute_input":"2023-09-20T22:56:01.161994Z","iopub.status.idle":"2023-09-20T22:56:01.236977Z","shell.execute_reply.started":"2023-09-20T22:56:01.16193Z","shell.execute_reply":"2023-09-20T22:56:01.236067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing the `bathrooms` column","metadata":{"id":"e26084f6"}},{"cell_type":"markdown","source":"Some values contained  “+” in this column and this was replaced with white space to remove the “+” from the values. \n","metadata":{"id":"005c9dce"}},{"cell_type":"code","source":"df.bathrooms = df.bathrooms.map(lambda x: int(x.strip().replace('+','')))\ndf","metadata":{"id":"e0b67fd0","outputId":"40e4efac-c28f-4f75-c24c-6f340656caac","execution":{"iopub.status.busy":"2023-09-20T22:56:01.238816Z","iopub.execute_input":"2023-09-20T22:56:01.240246Z","iopub.status.idle":"2023-09-20T22:56:01.294947Z","shell.execute_reply.started":"2023-09-20T22:56:01.240201Z","shell.execute_reply":"2023-09-20T22:56:01.293372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing the `floor` column","metadata":{"id":"2542859a"}},{"cell_type":"markdown","source":"Values were in the form of 1, 1+, G, 1 - 5, B - G and they were removed using a function which takes the last digit if it is in a range. For the values with ‘A’ (penthouse) or ‘M’ (middle floor), it was replaced with ‘nan’, ‘G’ (ground floor) was replaced with 0, ‘R’ (raised floor) was replaced with 0.5 to denote a raised floor and ‘B’ (basement) or ‘SB’ (semi-basement) was replaced with -1 to denote a basement.\n","metadata":{"id":"3b9be32d"}},{"cell_type":"code","source":"def floor_prep(floor):\n    '''\n    Function to preprocess floor feature.\n    \n    Parameters:\n        floor (str):The string containing the floor.\n\n\n    Returns:\n        float:floor value in int   \n    '''\n    \n    floor = str(floor)\n    floor = floor.strip()\n    floor = floor.split('-')[-1] # if range use the last value (higher value)\n    floor = floor.replace('+','')\n    floor = floor.strip()\n    \n    if 'G' in floor: # ground floor\n        return 0\n    elif 'A' in floor or 'M' in floor: # penthouse or middle floor so dont know the exact floor hence will ignore this value\n        return np.nan\n    elif 'R' in floor: # raised floor\n        return 0.5\n    elif 'B' in floor or 'SB' in floor: # basement or semi-basement\n        return -1\n    else:\n        return float(floor)","metadata":{"id":"85fd47af","execution":{"iopub.status.busy":"2023-09-20T22:56:01.297508Z","iopub.execute_input":"2023-09-20T22:56:01.298462Z","iopub.status.idle":"2023-09-20T22:56:01.361791Z","shell.execute_reply.started":"2023-09-20T22:56:01.298415Z","shell.execute_reply":"2023-09-20T22:56:01.360088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.floor = df.floor.map(floor_prep)\ndf","metadata":{"id":"180b2934","outputId":"c44fb444-d51b-4455-90d0-a63263a7800d","execution":{"iopub.status.busy":"2023-09-20T22:56:01.363675Z","iopub.execute_input":"2023-09-20T22:56:01.364861Z","iopub.status.idle":"2023-09-20T22:56:01.44374Z","shell.execute_reply.started":"2023-09-20T22:56:01.36481Z","shell.execute_reply":"2023-09-20T22:56:01.442459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing the `description` column ","metadata":{"id":"e76c37af"}},{"cell_type":"markdown","source":"Steps for preprocessing **description**:\n* lowercasing the text\n* removal of punctuations\n* removal of stopwords\n* lemmatization of text","metadata":{"id":"6f8d3733"}},{"cell_type":"code","source":"def lemmatize_words(text):\n    '''\n    Function to lemmatize text based on part of the speech.\n    \n    Parameters:\n        text (str):The string containing the text.\n\n\n    Returns:\n        str:Lemmitized text\n    '''\n    \n    lemmatizer = WordNetLemmatizer()\n    wordnet_map = {\"N\" : wordnet.NOUN, \"V\" : wordnet.VERB, \"J\" : wordnet.ADJ, \"R\" : wordnet.ADV}\n    \n    # word tokenization\n    word_tokens = nltk.word_tokenize(text)\n    \n    # part of speech tagger to tag the word tokens.\n    pos_tagged_text = nltk.pos_tag(word_tokens)#text.split())\n    \n    # lemmatization based on part of the speech\n    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])","metadata":{"id":"a6214e47","execution":{"iopub.status.busy":"2023-09-20T22:56:01.44555Z","iopub.execute_input":"2023-09-20T22:56:01.44682Z","iopub.status.idle":"2023-09-20T22:56:01.482034Z","shell.execute_reply.started":"2023-09-20T22:56:01.446761Z","shell.execute_reply":"2023-09-20T22:56:01.48028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def description_prep(df):\n    '''\n    Function to preprocess description feature.\n    \n    Parameters:\n        df (pandas.DataFrame):The dataset.\n\n\n    Returns:\n        pandas.DataFrame:The dataset containing new feature 'description_lem' for preprocessed and lemmitized description\n    '''\n    \n    # Lowercasing all the words\n    df['description_lem'] = df.description.str.lower()\n    \n    # Removal of punctuations\n    PUNCT_TO_REMOVE = string.punctuation + '“”–’°•€'\n    df['description_lem'] = df['description_lem'].apply(lambda text: text.translate(str.maketrans('', '', PUNCT_TO_REMOVE)))\n    \n    # Removal of stopwords\n    STOPWORDS = set(stopwords.words('english'))\n    df['description_lem'] = df['description_lem'].apply(lambda text: \" \".join([word for word in str(text).split() if word not in STOPWORDS]))\n    \n    # Lemmatization\n    df['description_lem'] = df['description_lem'].apply(lambda text: lemmatize_words(text))\n    \n    return df","metadata":{"id":"324f4374","execution":{"iopub.status.busy":"2023-09-20T22:56:01.483776Z","iopub.execute_input":"2023-09-20T22:56:01.484808Z","iopub.status.idle":"2023-09-20T22:56:01.538417Z","shell.execute_reply.started":"2023-09-20T22:56:01.48474Z","shell.execute_reply":"2023-09-20T22:56:01.536875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code to fix NLTK not finding wordnet in Kaggle notebooks\nimport subprocess\n\n# Download and unzip wordnet\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T22:56:01.540402Z","iopub.execute_input":"2023-09-20T22:56:01.540926Z","iopub.status.idle":"2023-09-20T22:56:02.273966Z","shell.execute_reply.started":"2023-09-20T22:56:01.540879Z","shell.execute_reply":"2023-09-20T22:56:02.272627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = description_prep(df)\ndf.head()","metadata":{"id":"9dfe6bf7","outputId":"ffb24fb1-df2d-4c7e-e579-17f959c1c7f5","execution":{"iopub.status.busy":"2023-09-20T22:56:02.27546Z","iopub.execute_input":"2023-09-20T22:56:02.276203Z","iopub.status.idle":"2023-09-20T22:56:33.956029Z","shell.execute_reply.started":"2023-09-20T22:56:02.276154Z","shell.execute_reply":"2023-09-20T22:56:33.95468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Missing Values Handling","metadata":{"id":"07a6103e"}},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"id":"12bf9251","execution":{"iopub.status.busy":"2023-09-20T22:56:33.957542Z","iopub.execute_input":"2023-09-20T22:56:33.957885Z","iopub.status.idle":"2023-09-20T22:56:33.972655Z","shell.execute_reply.started":"2023-09-20T22:56:33.957857Z","shell.execute_reply":"2023-09-20T22:56:33.970576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization & Plotting","metadata":{"id":"386e956b"}},{"cell_type":"markdown","source":"### Surface vs Price","metadata":{"id":"55806805"}},{"cell_type":"code","source":"sns.scatterplot(data=df, x='surface', y='price')\nplt.title('Surface vs Price')\nplt.show()","metadata":{"id":"991e80e5","outputId":"3918cac2-0628-45b2-9d85-33cdfd7dc2ab","execution":{"iopub.status.busy":"2023-09-20T22:56:33.974329Z","iopub.execute_input":"2023-09-20T22:56:33.97486Z","iopub.status.idle":"2023-09-20T22:56:34.756115Z","shell.execute_reply.started":"2023-09-20T22:56:33.974815Z","shell.execute_reply":"2023-09-20T22:56:34.754265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Its clear from the scatter plot that as surface increases the price of listing also increases.","metadata":{"id":"0b550347"}},{"cell_type":"markdown","source":"### Average Price based on No. of bathrooms:","metadata":{"id":"317a416c"}},{"cell_type":"code","source":"mean_price_by_baths = df.groupby('bathrooms').price.mean()\n\nsns.barplot(x=mean_price_by_baths.index, y=mean_price_by_baths)\nplt.title('Average Price based on No. of bathrooms')\nplt.show()","metadata":{"id":"9bca1b99","outputId":"88df5627-83e7-405c-a7cd-824d7c36ecc9","execution":{"iopub.status.busy":"2023-09-20T22:56:34.758578Z","iopub.execute_input":"2023-09-20T22:56:34.759212Z","iopub.status.idle":"2023-09-20T22:56:35.068576Z","shell.execute_reply.started":"2023-09-20T22:56:34.759163Z","shell.execute_reply":"2023-09-20T22:56:35.066904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the above bar graph, it is clear that the average price increases as the number of bathrooms increases in the listing where the average price of listings with 3 bathrooms is more than double that of two bathroom listings.","metadata":{"id":"e21b903c"}},{"cell_type":"markdown","source":"### Average Price based on No. of rooms","metadata":{"id":"b3d7b6e4"}},{"cell_type":"code","source":"mean_price_by_rooms = df.groupby('rooms').price.mean()\n\nsns.barplot(x=mean_price_by_rooms.index, y=mean_price_by_rooms)\nplt.title('Average Price based on No. of rooms')\nplt.show()","metadata":{"id":"aff664b9","outputId":"33c9f348-8c30-48f1-fdc3-16429b327368","execution":{"iopub.status.busy":"2023-09-20T22:56:35.070703Z","iopub.execute_input":"2023-09-20T22:56:35.07123Z","iopub.status.idle":"2023-09-20T22:56:35.368067Z","shell.execute_reply.started":"2023-09-20T22:56:35.071187Z","shell.execute_reply":"2023-09-20T22:56:35.367116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the graph, average price increases as the number of rooms increases in the listing with average price approx. twice for listings with 5 rooms than that of with 4 rooms.","metadata":{"id":"bb443ba5"}},{"cell_type":"markdown","source":"### Average Price based on Floor","metadata":{"id":"42d22833"}},{"cell_type":"code","source":"mean_price_by_floor = df.groupby('floor').price.mean()\n\nsns.barplot(x=mean_price_by_floor.index, y=mean_price_by_floor)\nplt.title('Average Price based on Floor')\nplt.show()","metadata":{"id":"f353400b","outputId":"4d45361a-f763-4eb2-9ca1-e10c44e9ff42","execution":{"iopub.status.busy":"2023-09-20T22:56:35.369222Z","iopub.execute_input":"2023-09-20T22:56:35.370512Z","iopub.status.idle":"2023-09-20T22:56:35.732861Z","shell.execute_reply.started":"2023-09-20T22:56:35.370478Z","shell.execute_reply":"2023-09-20T22:56:35.731419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph we can on average:\n* Listings on floors 3 and 4 have the highest price\n* Listings on higher floors and basements have the lowest price","metadata":{"id":"6301afd2"}},{"cell_type":"markdown","source":"## Pandas Profiling","metadata":{"id":"8a7ddcd9"}},{"cell_type":"markdown","source":"**Note:** Uncomment this section if required !!!","metadata":{}},{"cell_type":"markdown","source":"#### Generating the Profile Report","metadata":{"id":"2cc284ba"}},{"cell_type":"code","source":"# profile = ProfileReport(df, title=\"Profiling Report Post Data Wrangling\")","metadata":{"id":"976b400a","execution":{"iopub.status.busy":"2023-09-20T22:56:35.734145Z","iopub.execute_input":"2023-09-20T22:56:35.734469Z","iopub.status.idle":"2023-09-20T22:56:35.740006Z","shell.execute_reply.started":"2023-09-20T22:56:35.734441Z","shell.execute_reply":"2023-09-20T22:56:35.738757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Saving the report as HTML","metadata":{"id":"949dbf73"}},{"cell_type":"code","source":"# profile.to_file(\"profiling-report.html\")","metadata":{"id":"57bec026","outputId":"a35ed760-d9fb-49c6-88c2-ddfbc548546a","execution":{"iopub.status.busy":"2023-09-20T22:56:35.74173Z","iopub.execute_input":"2023-09-20T22:56:35.742133Z","iopub.status.idle":"2023-09-20T22:56:35.758379Z","shell.execute_reply.started":"2023-09-20T22:56:35.742102Z","shell.execute_reply":"2023-09-20T22:56:35.75657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outlier Detection\n\nWe performed outlier detection by plotting Boxplots on basis of IQR. Below are the boxplots for the continuous features:\n","metadata":{"id":"e6Znn0VFLBR4"}},{"cell_type":"markdown","source":"### Boxplot for Price","metadata":{"id":"1OyyaFsYLcWG"}},{"cell_type":"code","source":"sns.boxplot(data=df, x='price')","metadata":{"id":"JYsvSaZtLhLC","outputId":"373e9712-08fe-4def-d621-b3a6a8fb621f","execution":{"iopub.status.busy":"2023-09-20T22:56:35.761727Z","iopub.execute_input":"2023-09-20T22:56:35.762771Z","iopub.status.idle":"2023-09-20T22:56:36.026166Z","shell.execute_reply.started":"2023-09-20T22:56:35.762691Z","shell.execute_reply":"2023-09-20T22:56:36.024519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boxplot for Surface","metadata":{"id":"5l_eMzPCLhnM"}},{"cell_type":"code","source":"sns.boxplot(data=df, x='surface')","metadata":{"id":"wdsHXt0fLj1p","outputId":"b52c831e-590f-4beb-b203-a07caf9775f7","execution":{"iopub.status.busy":"2023-09-20T22:56:36.028166Z","iopub.execute_input":"2023-09-20T22:56:36.02857Z","iopub.status.idle":"2023-09-20T22:56:36.267311Z","shell.execute_reply.started":"2023-09-20T22:56:36.028538Z","shell.execute_reply":"2023-09-20T22:56:36.266167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boxplot for Floor","metadata":{"id":"ftstnsP5LkQd"}},{"cell_type":"code","source":"sns.boxplot(data=df, x='floor')","metadata":{"id":"8uLVhSAzLm7y","outputId":"f08a0e7b-3431-472d-d68a-4b3065cb7420","execution":{"iopub.status.busy":"2023-09-20T22:56:36.268996Z","iopub.execute_input":"2023-09-20T22:56:36.269361Z","iopub.status.idle":"2023-09-20T22:56:36.512343Z","shell.execute_reply.started":"2023-09-20T22:56:36.269329Z","shell.execute_reply":"2023-09-20T22:56:36.511199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Why we did not remove outliers?\n- In some circumstances, domain expertise can be utilized in place of statistical methods to detect and manage outliers. Outliers in the “price” variable in real estate datasets represents legitimate properties with high price and should not be eliminated. \n- A few outliers in the dataset are less likely to have an impact on clustering techniques like K-means or K-means++ since they are intrinsically resistant to outliers.\n- Since we have a small-sized dataset consisting of only around 1600 rows, removing outliers from a small dataset may drastically limit the quantity of data available for analysis, perhaps producing skewed or incorrect conclusions. Hence, we decided not to remove any outliers.\n\n\n\n","metadata":{"id":"0M5qVlpcLIyF"}},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{"id":"ba58ecee"}},{"cell_type":"markdown","source":"To reach our goal where we need to performed a clustering analysis on the house's description (called the **description cluster or TF-IDF cluster**) and five other attributes of the house listing ('price', 'rooms', 'surface', 'bathrooms', 'floor') called the **feature cluster**, we will divide the dataset in two data frames:\n1. **Feature data frame:** the combination of five attributes- price, rooms, surface, bathrooms and floor\n2. **TFIDF data frame:** house’s description_lem column (the one obtained after cleaning the description feature)\n","metadata":{"id":"80aaa238"}},{"cell_type":"markdown","source":"### Data Frame with price, rooms, surface, bathrooms and floor","metadata":{"id":"c31c8727"}},{"cell_type":"code","source":"df_features = df[['price', 'rooms', 'surface', 'bathrooms', 'floor']]\ndf_features.head()","metadata":{"id":"b0abe8b8","outputId":"27f45028-b3fc-44ce-c967-46de4576c0dc","execution":{"iopub.status.busy":"2023-09-20T22:56:36.513446Z","iopub.execute_input":"2023-09-20T22:56:36.513826Z","iopub.status.idle":"2023-09-20T22:56:36.533039Z","shell.execute_reply.started":"2023-09-20T22:56:36.51378Z","shell.execute_reply":"2023-09-20T22:56:36.532062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TFIDF Data Frame from description","metadata":{"id":"9f483e3e"}},{"cell_type":"code","source":"tfidf = TfidfVectorizer()\n\nX_tfidf = tfidf.fit_transform(df['description_lem'])","metadata":{"id":"632c8139","execution":{"iopub.status.busy":"2023-09-20T22:56:36.53437Z","iopub.execute_input":"2023-09-20T22:56:36.535142Z","iopub.status.idle":"2023-09-20T22:56:36.919525Z","shell.execute_reply.started":"2023-09-20T22:56:36.535109Z","shell.execute_reply":"2023-09-20T22:56:36.918005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tfidf = pd.DataFrame(\n    data=X_tfidf.toarray(),\n    columns=tfidf.get_feature_names_out()\n)","metadata":{"id":"5640c72b","execution":{"iopub.status.busy":"2023-09-20T22:56:36.921287Z","iopub.execute_input":"2023-09-20T22:56:36.921766Z","iopub.status.idle":"2023-09-20T22:56:37.412679Z","shell.execute_reply.started":"2023-09-20T22:56:36.921718Z","shell.execute_reply":"2023-09-20T22:56:37.411053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tfidf.shape","metadata":{"id":"7a9d66f4","outputId":"19f2f4db-8192-4922-c565-3a1486f0c28d","execution":{"iopub.status.busy":"2023-09-20T22:56:37.414778Z","iopub.execute_input":"2023-09-20T22:56:37.416009Z","iopub.status.idle":"2023-09-20T22:56:37.424639Z","shell.execute_reply.started":"2023-09-20T22:56:37.415946Z","shell.execute_reply":"2023-09-20T22:56:37.423173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualizing the word occurrences","metadata":{"id":"5534c3a7"}},{"cell_type":"code","source":"def count_plot_words_occurrences(df, figsize=(15,8), xticks_start=0, xticks_end=None):\n    \"\"\"\n    For each word in tfidf dataframe it counts the occurences of the words in all the announcements\n    \n    Parameters:\n        df (pandas.DataFrame): TFIDF dataset\n        figsize: Dimension of the plot\n        xticks_start: Axis x attribute for the plot (default value: 0)\n        xticks_end:   Axis x attribute for the plot (default value: number of columns)\n        steps:        Axis x attribute for the plot (default value: 1000)\n    \"\"\"\n         \n    words_counting = []\n\n    # put NaN values if there's 0\n    df = df.where(df != 0)\n \n    for i in df:\n        cnt_word = df.loc[:, i].count()\n        words_counting.append(int(cnt_word))\n        \n    # if there is no input about xticks_end the assign default value i.e. total number of columns\n    if xticks_end is None:\n        xticks_end = len(df.iloc[0])\n\n    plt.figure(figsize=figsize)\n \n    x = range(xticks_start, xticks_end)\n\n    plt.plot(x, words_counting, 'ro')\n    \n    plt.xlabel('Word_ID', size = 15)\n    plt.ylabel('Listings containing the word_ID', size = 10)\n    plt.title('Distribution of the words over the listings', size=12)\n    \n    plt.grid(linestyle='--', color='lightgray', zorder = 0)    \n\n    plt.show()\n    \n    return","metadata":{"id":"20c5e794","execution":{"iopub.status.busy":"2023-09-20T22:56:37.426667Z","iopub.execute_input":"2023-09-20T22:56:37.427169Z","iopub.status.idle":"2023-09-20T22:56:37.441369Z","shell.execute_reply.started":"2023-09-20T22:56:37.427133Z","shell.execute_reply":"2023-09-20T22:56:37.440321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp = pd.DataFrame(\n    data=X_tfidf.toarray())","metadata":{"id":"01562417","execution":{"iopub.status.busy":"2023-09-20T22:56:37.451341Z","iopub.execute_input":"2023-09-20T22:56:37.452198Z","iopub.status.idle":"2023-09-20T22:56:37.93846Z","shell.execute_reply.started":"2023-09-20T22:56:37.452158Z","shell.execute_reply":"2023-09-20T22:56:37.937062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Looking at the occurence of first 1000 words in all the dataframe","metadata":{"id":"6e753151"}},{"cell_type":"code","source":"count_plot_words_occurrences(df_temp.loc[:,0:1000], xticks_start=0, xticks_end=1001)","metadata":{"id":"ed5bcda1","outputId":"e4c3813c-3b34-464d-e575-29a40bbe2cea","execution":{"iopub.status.busy":"2023-09-20T22:56:37.940243Z","iopub.execute_input":"2023-09-20T22:56:37.94063Z","iopub.status.idle":"2023-09-20T22:56:38.479529Z","shell.execute_reply.started":"2023-09-20T22:56:37.940597Z","shell.execute_reply":"2023-09-20T22:56:38.477891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Looking at the occurrence of the last 1000 words of the document ","metadata":{"id":"aeeb8f42"}},{"cell_type":"code","source":"count_plot_words_occurrences(df_temp.loc[:,11000:], xticks_start=11000, xticks_end=len(df_temp.iloc[0]))","metadata":{"id":"df723db6","outputId":"3a07787c-0fab-4c87-82a7-6ffe1ebd96de","execution":{"iopub.status.busy":"2023-09-20T22:56:38.48193Z","iopub.execute_input":"2023-09-20T22:56:38.482502Z","iopub.status.idle":"2023-09-20T22:56:40.082367Z","shell.execute_reply.started":"2023-09-20T22:56:38.482454Z","shell.execute_reply":"2023-09-20T22:56:40.080807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the above two plots, we have a lot of words that compare only once in all the documents.","metadata":{"id":"b77bf01f"}},{"cell_type":"markdown","source":"## Normalization","metadata":{"id":"12d38e9f"}},{"cell_type":"markdown","source":"Since there were no categorical columns (except title and description) that we need for clustering analysis, we only used **StandardScaler()** function of scikit-learn is used to normalize the five numerical feature columns ('price', 'rooms', 'surface', 'bathrooms', 'floor') into a standard range.\n","metadata":{"id":"d929b7cd"}},{"cell_type":"code","source":"scaler = StandardScaler()\ndata_transformed = scaler.fit_transform(df_features)","metadata":{"id":"818ea070","execution":{"iopub.status.busy":"2023-09-20T22:56:40.08403Z","iopub.execute_input":"2023-09-20T22:56:40.084431Z","iopub.status.idle":"2023-09-20T22:56:40.095078Z","shell.execute_reply.started":"2023-09-20T22:56:40.084399Z","shell.execute_reply":"2023-09-20T22:56:40.093809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_features_norm = pd.DataFrame(data=data_transformed, columns=['price', 'rooms', 'surface', 'bathrooms', 'floor'])\ndf_features_norm.head()","metadata":{"id":"61522ccd","outputId":"76a81f1d-adde-4efd-beb1-66f55694680e","execution":{"iopub.status.busy":"2023-09-20T22:56:40.096541Z","iopub.execute_input":"2023-09-20T22:56:40.096936Z","iopub.status.idle":"2023-09-20T22:56:40.118594Z","shell.execute_reply.started":"2023-09-20T22:56:40.096904Z","shell.execute_reply":"2023-09-20T22:56:40.116968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building (using K-Means++ Clustering)","metadata":{"id":"30fd5c19"}},{"cell_type":"markdown","source":"### Function for elbow method","metadata":{"id":"485903ec"}},{"cell_type":"code","source":"def elbow_method (data, max_clusters=10, TFIDF = False, figsize=(12,8)):\n    \n    n_listings = len(data)\n    n_features = len(data.iloc[0])\n    \n    plot_labels = [\n        ['Number of clusters (k)', 'Inertia (sum of squared distance)', 'Elbow-Method for features_dataframe'],\n        ['Number of clusters (k)', 'Inertia (sum of squared distance)', f'Elbow Method for {n_listings} listings based on {n_features} features']\n    ]\n    \n    labels_idx = 0\n    \n    if TFIDF == True:\n        labels_idx = 1\n       \n                                                               \n    ssd = dict()\n        \n    for k in range(2, max_clusters+1):\n        model = KMeans(n_clusters=k, init='k-means++')\n        model = model.fit(data)\n        ssd[k] = model.inertia_\n        \n        \n    # plotting the elbow method\n    \n    fig = plt.figure(figsize=figsize)\n    x = list(ssd.keys())\n    y = list(ssd.values())\n    \n    plt.plot(x, y, 'bx-')\n    plt.xlabel(plot_labels[labels_idx][0], size=15)\n    plt.ylabel(plot_labels[labels_idx][1], size=13)\n    plt.title(plot_labels[labels_idx][2], size=15)\n    plt.grid(linestyle='--', linewidth=2, color='lightgray', zorder = 0)    \n    \n    if TFIDF is False:\n        plt.xticks(np.arange(2, max_clusters+1))\n    \n    plt.show()\n    \n    return ","metadata":{"id":"ac3ba56a","execution":{"iopub.status.busy":"2023-09-20T22:56:40.120451Z","iopub.execute_input":"2023-09-20T22:56:40.120926Z","iopub.status.idle":"2023-09-20T22:56:40.134543Z","shell.execute_reply.started":"2023-09-20T22:56:40.120892Z","shell.execute_reply":"2023-09-20T22:56:40.13323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-Means with features data frame","metadata":{"id":"a8a8e4b3"}},{"cell_type":"markdown","source":"#### Applying elbow method","metadata":{"id":"e13c3c3a"}},{"cell_type":"code","source":"elbow_method(df_features_norm)","metadata":{"id":"ff018b4b","outputId":"66b3f775-6733-4a99-e775-3a1354a02c84","execution":{"iopub.status.busy":"2023-09-20T22:56:40.136192Z","iopub.execute_input":"2023-09-20T22:56:40.13693Z","iopub.status.idle":"2023-09-20T22:56:42.356213Z","shell.execute_reply.started":"2023-09-20T22:56:40.136893Z","shell.execute_reply":"2023-09-20T22:56:42.354672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the above graph we select **k=5** as the most appropriate number of clusters.\n","metadata":{"id":"e245e70d"}},{"cell_type":"markdown","source":"#### Model creation","metadata":{"id":"86e37b65"}},{"cell_type":"markdown","source":"Then, we applied the KMeans clustering algorithm with 5 clusters to the features dataframe and assigned each data point to its corresponding cluster. The resulting cluster labels are added as a new column “features_cluster” to the original dataframe.","metadata":{"id":"O3KQYYA1Ns_B"}},{"cell_type":"code","source":"model = KMeans(n_clusters=5, random_state=1234, init='k-means++')\nmodel.fit(data_transformed)\n\nclusters = model.predict(data_transformed)","metadata":{"id":"8bfbd252","execution":{"iopub.status.busy":"2023-09-20T22:56:42.358187Z","iopub.execute_input":"2023-09-20T22:56:42.35857Z","iopub.status.idle":"2023-09-20T22:56:42.43057Z","shell.execute_reply.started":"2023-09-20T22:56:42.358538Z","shell.execute_reply":"2023-09-20T22:56:42.429298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['features_cluster'] = clusters\ndf.head()","metadata":{"id":"cd43344e","outputId":"d5599cf9-0e34-441a-a150-9955b450350b","execution":{"iopub.status.busy":"2023-09-20T22:56:42.432503Z","iopub.execute_input":"2023-09-20T22:56:42.432926Z","iopub.status.idle":"2023-09-20T22:56:42.453516Z","shell.execute_reply.started":"2023-09-20T22:56:42.432892Z","shell.execute_reply":"2023-09-20T22:56:42.452501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.groupby('features_cluster').price.count()\n\nsns.barplot(x=data.index, y=data)\nplt.title('Count of data in each feature clusters')\nplt.ylabel('Count')\nplt.show()","metadata":{"id":"b3745548","outputId":"f7b0edd0-ba5d-4b74-ae08-4abc132c54d5","execution":{"iopub.status.busy":"2023-09-20T22:56:42.455275Z","iopub.execute_input":"2023-09-20T22:56:42.455974Z","iopub.status.idle":"2023-09-20T22:56:42.752394Z","shell.execute_reply.started":"2023-09-20T22:56:42.45594Z","shell.execute_reply":"2023-09-20T22:56:42.751465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above bar plot shows the count of data points in each feature cluster that helps to visualize the distribution of data points across the different feature clusters.\n","metadata":{"id":"YbRbm7Diw6GE"}},{"cell_type":"markdown","source":"### K-Means with TFIDF","metadata":{"id":"dcf96cac"}},{"cell_type":"markdown","source":"#### Applying elbow method","metadata":{"id":"b309188c"}},{"cell_type":"code","source":"elbow_method(df_tfidf, TFIDF=True)","metadata":{"id":"f5ee6a0c","outputId":"28d3c2f8-23ae-4c67-e04e-f89d2c31b730","execution":{"iopub.status.busy":"2023-09-20T22:56:42.754226Z","iopub.execute_input":"2023-09-20T22:56:42.754943Z","iopub.status.idle":"2023-09-20T22:58:31.667806Z","shell.execute_reply.started":"2023-09-20T22:56:42.754909Z","shell.execute_reply":"2023-09-20T22:58:31.666116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model creation","metadata":{"id":"7a0329d7"}},{"cell_type":"markdown","source":"Since our goal is to compare the similarities of clusters we will fix the **number of clusters (k) to 5** as we got from the **features data frame**.\n\nSimilarly, we could depict the frequency of data points in each cluster of the TF-IDF dataframe (containing the description of the house) and assign each data point a “TFIDF_cluster” label after fitting the TF-IDF dataframe in K-means++ model.\n","metadata":{"id":"9d8f21a2"}},{"cell_type":"code","source":"model = KMeans(n_clusters=5, random_state=1234, init='k-means++')\nmodel.fit(df_tfidf)\n\nclusters = model.predict(df_tfidf)\n\ndf['TFIDF_cluster'] = clusters\ndf.head()","metadata":{"id":"bbd57172","outputId":"352dd218-2d06-4ca8-9646-b67acb50b171","execution":{"iopub.status.busy":"2023-09-20T22:58:31.66972Z","iopub.execute_input":"2023-09-20T22:58:31.670464Z","iopub.status.idle":"2023-09-20T22:58:44.639819Z","shell.execute_reply.started":"2023-09-20T22:58:31.670426Z","shell.execute_reply":"2023-09-20T22:58:44.638628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.groupby('TFIDF_cluster').price.count()\n\nsns.barplot(x=data.index, y=data)\nplt.title('Count of data in each TFIDF clusters')\nplt.ylabel('Count')\nplt.show()","metadata":{"id":"ca657698","outputId":"1d1f4988-c405-4604-b2f3-b5423dbd4e02","execution":{"iopub.status.busy":"2023-09-20T22:58:44.641112Z","iopub.execute_input":"2023-09-20T22:58:44.641676Z","iopub.status.idle":"2023-09-20T22:58:44.914506Z","shell.execute_reply.started":"2023-09-20T22:58:44.641644Z","shell.execute_reply":"2023-09-20T22:58:44.913104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Jaccard similarity between two matrices clusters\n\nWe will only consider the two columns:\n* **features_cluster**\n* **TFIDF_cluster**\n\nAnd create a dataframe named **df_j** for the Jaccard-similarity.","metadata":{"id":"412a7a20"}},{"cell_type":"code","source":"df_j = pd.DataFrame()\ndf_j = df[[ 'description', 'features_cluster', 'TFIDF_cluster']]\n\ndf_j.head()","metadata":{"id":"93e69376","outputId":"7e763389-ff9f-4f7d-a66e-9f66f22c395f","execution":{"iopub.status.busy":"2023-09-20T22:58:44.916448Z","iopub.execute_input":"2023-09-20T22:58:44.916876Z","iopub.status.idle":"2023-09-20T22:58:44.935777Z","shell.execute_reply.started":"2023-09-20T22:58:44.916841Z","shell.execute_reply":"2023-09-20T22:58:44.933889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Grouping the data w.r.t. clusters","metadata":{"id":"7ae9111b"}},{"cell_type":"markdown","source":"We now create two dictionaries to represent the two cluster groups.\n\nEach dict will include the number associated with the cluster as its key and all of the documents in that cluster as its value.\n\n\nExample:\n\n|keys(cluster number)   |  values(list of listing indices)  |\n|-----------------|---------------------------------|\n|    0            | [1, 7, 35, 74]                      |      \n|    1            | [6, 11, 100]                       |\n|    2            | [3, 128, 153]                     |","metadata":{"id":"69802145"}},{"cell_type":"code","source":"features_clusters = defaultdict(list)\nTFIDF_clusters = defaultdict(list)\n\nfor i in range(len(df_j)):\n    k1 = df_j.iloc[i]['features_cluster']\n    k2 = df_j.iloc[i]['TFIDF_cluster']\n    \n    features_clusters[k1].append(i)\n    TFIDF_clusters[k2].append(i)","metadata":{"id":"74b62408","execution":{"iopub.status.busy":"2023-09-20T22:58:44.937636Z","iopub.execute_input":"2023-09-20T22:58:44.938093Z","iopub.status.idle":"2023-09-20T22:58:45.236129Z","shell.execute_reply.started":"2023-09-20T22:58:44.938058Z","shell.execute_reply":"2023-09-20T22:58:45.234816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard_similarity(set1, set2):\n    '''\n    Function to calculte the Jaccard-similarity score on two sets.\n    \n    Parameters:\n        set1 (set):Data in form of set\n        set2 (set):Data in form of set\n\n    Returns:\n        float: Jaccard-similarity score\n    '''\n    \n    # set the two lists, in order to mac\n    set1 = set(set1)\n    set2 = set(set2)\n    \n    intersection = set1.intersection(set2)\n    union = set1.union(set2)\n    jaccard_similarity = len(intersection) / float(len(union))\n    \n    return jaccard_similarity","metadata":{"id":"3bde2ca2","execution":{"iopub.status.busy":"2023-09-20T22:58:45.237877Z","iopub.execute_input":"2023-09-20T22:58:45.238254Z","iopub.status.idle":"2023-09-20T22:58:45.246533Z","shell.execute_reply.started":"2023-09-20T22:58:45.238222Z","shell.execute_reply":"2023-09-20T22:58:45.244666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_jaccard_similarities(features_clusters, TFIDF_clusters):\n    '''\n    Function to calculate the Jaccard-similarities on pairs of feature clusters and TFIDF clusters.\n    \n    Parameters:\n        features_clusters (dict): Grouped data based on feature clusters\n        TFIDF_clusters (dict): Grouped data based on TFIDF clusters\n\n    Returns:\n        list: List of tuples consisting of cluster pairs and their Jaccard-similarity score\n    '''\n    \n    jaccard_scores_list = []\n    \n    for cl1 in features_clusters.keys():\n        for cl2 in TFIDF_clusters.keys():\n            \n            j_score = jaccard_similarity(features_clusters[cl1], TFIDF_clusters[cl2])\n            \n            jaccard_scores_list.append(tuple([(cl1, cl2), j_score]))\n    \n    jaccard_scores_list.sort(key = lambda x: x[1], reverse=True) # Sorting in descending order based on jaccard-similarity score\n    \n    return jaccard_scores_list","metadata":{"id":"db22e72f","execution":{"iopub.status.busy":"2023-09-20T22:58:45.248293Z","iopub.execute_input":"2023-09-20T22:58:45.248699Z","iopub.status.idle":"2023-09-20T22:58:45.267136Z","shell.execute_reply.started":"2023-09-20T22:58:45.248656Z","shell.execute_reply":"2023-09-20T22:58:45.265722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculating the Jaccard-similarities","metadata":{"id":"6d9c5b4c"}},{"cell_type":"code","source":"jaccard_similarities = calculate_jaccard_similarities(features_clusters, TFIDF_clusters)","metadata":{"id":"8277e60c","execution":{"iopub.status.busy":"2023-09-20T22:58:45.269183Z","iopub.execute_input":"2023-09-20T22:58:45.26965Z","iopub.status.idle":"2023-09-20T22:58:45.28948Z","shell.execute_reply.started":"2023-09-20T22:58:45.269606Z","shell.execute_reply":"2023-09-20T22:58:45.288324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_j_score = pd.DataFrame(data=jaccard_similarities, columns=['Cluster pair', 'Jaccard-similarity score'])\n\nplt.figure(figsize=(10, 8))\nsns.barplot(data=df_j_score, y='Cluster pair', x='Jaccard-similarity score', orient='h')\nplt.title('Jaccard-similarity scores for cluster pairs (feature cluster, TFIDF cluster)')\nplt.show()","metadata":{"id":"592fa58b","outputId":"87b4a708-311d-4d9a-d1f9-f59466a057fc","execution":{"iopub.status.busy":"2023-09-20T22:58:45.291046Z","iopub.execute_input":"2023-09-20T22:58:45.292091Z","iopub.status.idle":"2023-09-20T22:58:45.92241Z","shell.execute_reply.started":"2023-09-20T22:58:45.292042Z","shell.execute_reply":"2023-09-20T22:58:45.920984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above figure shows the Jaccard Similarity score for each cluster pair (feature cluster, TFIDF cluster) in decreasing order.\n\n**Since all the Jaccard-similarity scores are approx. 0.2 or less, we came to conclusion that the description provided by the owner in the listings don't completely match with specifications of the listings.**","metadata":{"id":"4588d2db"}},{"cell_type":"markdown","source":"## Wordcloud of best pair based on Jaccard-similarity","metadata":{"id":"558bb317"}},{"cell_type":"markdown","source":"Finally, we made a word cloud from the house description of the best pair based on the highest Jaccard similarity score as shown below.\n","metadata":{"id":"T4eDXsIUON3v"}},{"cell_type":"code","source":"def doWordcloud(text):\n    '''\n    Function to create word cloud.\n    \n    Parameters:\n        text (str): Text document or corpus\n    '''\n    # Create stopword list:\n    stopwords = set(STOPWORDS)\n\n    if path.exists('house_mask.png') or path.exists('/kaggle/input/house_mask.png'):\n        house_mask = np.array(Image.open(\"house_mask.png\"))\n    \n        wc = WordCloud(background_color=\"white\", max_words=500, mask=house_mask,\n                       stopwords=stopwords, contour_width=4, contour_color='firebrick')\n    else:\n        wc = WordCloud(background_color=\"white\", max_words=500, stopwords=stopwords)\n    \n    # Generate a wordcloud\n    wc.generate(text)\n\n    fig = plt.figure(figsize=[20,10])\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.axis(\"off\")\n    fig.show()\n    \n    return","metadata":{"id":"8fa0c400","execution":{"iopub.status.busy":"2023-09-20T22:58:45.924515Z","iopub.execute_input":"2023-09-20T22:58:45.924989Z","iopub.status.idle":"2023-09-20T22:58:45.93477Z","shell.execute_reply.started":"2023-09-20T22:58:45.924954Z","shell.execute_reply":"2023-09-20T22:58:45.933583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def setWordcloud (df_j, list_cluster1, list_cluster2):\n    '''\n    Function to create word cloud of pair of clusters given.\n    \n    Parameters:\n        df_j (pd.DataFrame): Jaccard dataframe\n        list_cluster1 (list): List of data values in the cluster\n        list_cluster2 (list): List of data values in the cluster\n    '''\n    \n    listing = (list_cluster1 + list_cluster2)\n\n    description = str()\n    for i in listing:\n        description += str(df_j.iloc[i]['description'])\n    \n    doWordcloud(description)\n    \n    return","metadata":{"id":"160958b4","execution":{"iopub.status.busy":"2023-09-20T22:58:45.936441Z","iopub.execute_input":"2023-09-20T22:58:45.937634Z","iopub.status.idle":"2023-09-20T22:58:45.95466Z","shell.execute_reply.started":"2023-09-20T22:58:45.937594Z","shell.execute_reply":"2023-09-20T22:58:45.953225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the wordcloud","metadata":{"id":"0fa062e3","outputId":"bd67e340-e481-4eed-9a8e-d1a24dece56f"}},{"cell_type":"code","source":"setWordcloud(df_j, features_clusters[1], TFIDF_clusters[2])","metadata":{"id":"4fd9eec8","outputId":"bd67e340-e481-4eed-9a8e-d1a24dece56f","execution":{"iopub.status.busy":"2023-09-20T22:58:45.956412Z","iopub.execute_input":"2023-09-20T22:58:45.956911Z","iopub.status.idle":"2023-09-20T22:58:48.084487Z","shell.execute_reply.started":"2023-09-20T22:58:45.956873Z","shell.execute_reply":"2023-09-20T22:58:48.083137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\nThrough this assignment, we learned, implemented, and accomplished all the basic machine learning modeling steps, starting from scraping data from a real estate website and converting it into a CSV file with the scraped house listing details. Then, we moved on to the data wrangling process. We learned how to clean numerical and categorical valued columns using regular expressions and NLP techniques like lemmatization, punctuation and stopwords removal. \n\nWe applied data visualization techniques to infer the relationships and trends, for instance, among the average price of the house and other features. Pandas' profile was also created for our dataset and saved into an HTML file. After normalization on the dataset and using the Elbow method, we determined that 5 clusters are quite optimal and then applied the K-Means++ clustering algorithm to derive the clusters for two clustering groups - the feature cluster and TFIDF cluster. Finally, we calculated the Jaccard Similarity score for each cluster pair, and most of the scores were approximately 0.2 or lesser. Hence, the description provided by the owner in the listings does not wholly match other real estate listings specifications such as price, bathrooms, floors etc.\n\n\n","metadata":{"id":"51LdrUJHOQmN"}},{"cell_type":"code","source":"","metadata":{"id":"af3831cf"},"execution_count":null,"outputs":[]}]}